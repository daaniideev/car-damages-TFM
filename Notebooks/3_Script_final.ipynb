{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368d8168-2975-4cbd-a0d8-2b0f8365bc29",
   "metadata": {},
   "source": [
    "# Creación del modelo final:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21421db3-612f-42ad-996a-1b207c5ee00a",
   "metadata": {},
   "source": [
    "En el siguiente Notebook se prepara el script final donde se integran ambos modelos. Posteriormente, este Notebook se adaptará para convertirse en un archivo '.py', permitiendo su uso como un endpoint en el entorno de producción que se montará haciendo uso de EC2 de AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0c553-60d3-4393-97ea-b11858be3f44",
   "metadata": {},
   "source": [
    "En este Notebook se muestra todo el código y explicaciones importantes de este, pero la explicación detallada se encuentra en la memoria del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719c719-f4d1-4b7c-954e-d4b178e30b2f",
   "metadata": {},
   "source": [
    "## Preparación del entorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af754c86-296a-46bc-b244-3d7ded4be859",
   "metadata": {},
   "source": [
    "### Instalación de dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feed938e-7932-4ed8-8627-08e78af9fa5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\usuario\\anaconda3\\lib\\site-packages (8.3.61)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.65-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.65-py3-none-any.whl (911 kB)\n",
      "   ---------------------------------------- 0.0/911.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 911.6/911.6 kB 13.8 MB/s eta 0:00:00\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.3.61\n",
      "    Uninstalling ultralytics-8.3.61:\n",
      "      Successfully uninstalled ultralytics-8.3.61\n",
      "Successfully installed ultralytics-8.3.65\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\usuario\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ultralytics\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8b36a0-6680-4ab3-b02d-8d4217a4a8f8",
   "metadata": {},
   "source": [
    "### Importación de librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ef37e9-252d-4223-932b-8ff88e8fd962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d144548-65d2-4ecd-8aa6-468ab38e7cd7",
   "metadata": {},
   "source": [
    "### Definición de funciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e8bf6-6b39-4321-92e9-0d28e3b3f981",
   "metadata": {},
   "source": [
    "Funcion que guarda los frames de un video en un array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd76b37e-2ae8-4f3d-9d03-068f1026c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertVideoToFramesArray(video_path):\n",
    "\tframes_array = []\n",
    "\tcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\tif not cap.isOpened():\n",
    "\t\t\tprint(\"Error al abrir el archivo de video\")\n",
    "\telse:\n",
    "\t\t\ttotal_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\t\t\tfor frame_index in range(total_frames):\n",
    "\t\t\t\t\tret, frame = cap.read()\n",
    "\t\t\t\t\tif not ret:\n",
    "\t\t\t\t\t\t\tprint(f\"No se pudo leer el frame {frame_index}\")\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tframes_array.append(frame)\n",
    "\n",
    "\t\t\tcap.release()\n",
    "\treturn frames_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae946e-df57-4fdf-bcbd-f49acdc08516",
   "metadata": {},
   "source": [
    "Función que permite crear txt con las coordenadas del cuadrado de la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c3e7e8-e20c-49a1-94d6-78816d2ed5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTxtFile(damagesArray, fileName, coordenadas):\n",
    "    damages_dict = {\n",
    "        \"broken lamp\": 0,\n",
    "        \"glass shatter\": 1,\n",
    "        \"scratch\": 2,\n",
    "        \"dent\": 3,\n",
    "        \"tire flat\": 4,\n",
    "    }\n",
    "\n",
    "    if os.path.exists(fileName):\n",
    "        os.remove(fileName)\n",
    "\n",
    "    content = ''\n",
    "\n",
    "    if 'no-damage' not in damagesArray:\n",
    "        for element in damagesArray:\n",
    "            damageNum = damages_dict[element]\n",
    "            content = content + str(damageNum) + ' ' + coordenadas + '\\n'\n",
    "\n",
    "    with open(fileName, \"w\") as file:\n",
    "        file.write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70823c-4a33-4792-b5ce-ea748ccce31e",
   "metadata": {},
   "source": [
    "Funcion que calcula la similitud entre dos imágenes mediante la correlación de sus histogramas en escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61f50d7-0565-4d80-87e7-3dcb22862dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_similitud_histograma(imagen1, imagen2):\n",
    "    # Convertir las imágenes a escala de grises\n",
    "    imagen1_gray = cv2.cvtColor(imagen1, cv2.COLOR_BGR2GRAY)\n",
    "    imagen2_gray = cv2.cvtColor(imagen2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcular los histogramas de las dos imágenes\n",
    "    hist1 = cv2.calcHist([imagen1_gray], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([imagen2_gray], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # Normalizar los histogramas\n",
    "    hist1 = cv2.normalize(hist1, hist1).flatten()\n",
    "    hist2 = cv2.normalize(hist2, hist2).flatten()\n",
    "\n",
    "    # Calcular la correlación entre los histogramas\n",
    "    similitud = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    \n",
    "    # Convertir la similitud en porcentaje\n",
    "    similitud_porcentaje = similitud\n",
    "    \n",
    "    return similitud_porcentaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038564a1-f9b6-4ba5-9cc5-b087d21f43de",
   "metadata": {},
   "source": [
    "Funcion que recorta una región específica de una imagen original utilizando coordenadas normalizadas y devuelve la imagen recortada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95eccdd-bb10-4f05-985d-9b2f73a8e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_imagen(parte_de_la_imagen_xyxyn, imagen_original):\n",
    "    if len(parte_de_la_imagen_xyxyn) != 4 or any(not isinstance(coord, (float, int)) for coord in parte_de_la_imagen_xyxyn):\n",
    "        raise ValueError(\"Las coordenadas deben ser una lista de cuatro valores numéricos [x_min, y_min, x_max, y_max].\")\n",
    "    \n",
    "    x_min, y_min, x_max, y_max = parte_de_la_imagen_xyxyn\n",
    "    h, w, _ = imagen_original.shape\n",
    "    \n",
    "    x_min = max(0, int(x_min * w))\n",
    "    y_min = max(0, int(y_min * h))\n",
    "    x_max = min(w, int(x_max * w))\n",
    "    y_max = min(h, int(y_max * h))\n",
    "    \n",
    "    imagen_recortada = imagen_original[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    if imagen_recortada.size == 0:\n",
    "        print(f\"Recorte vacío: coordenadas fuera de los límites de la imagen.\")\n",
    "    \n",
    "    return imagen_recortada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d07ff-b0a3-479a-937c-8a053a95761a",
   "metadata": {},
   "source": [
    "Función que recibe un daño y una parte del vehículo y devuelve True si se puede dar dicho daño en dicha parte (por ejemplo, rallajo en puerta trasera) y False si no se puede dar dicho daño en dicha parte (por ejemplo, faro roto en puerta trasera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9eaf6e-87e0-41db-856a-53946924a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_damage_possible(nombre_de_clase_2, numero_de_clase):\n",
    "    diccionario_combinaciones_posibles = {\n",
    "        0: ['scratch', 'dent'],\n",
    "        1: ['tire flat'],\n",
    "        2: ['glass shatter'],\n",
    "        3: ['scratch', 'dent'],\n",
    "        4: ['scratch', 'dent'],\n",
    "        5: ['scratch', 'dent'],\n",
    "        6: [],\n",
    "        7: ['glass shatter'],\n",
    "        8: ['glass shatter'],\n",
    "        9: ['scratch', 'dent'],\n",
    "        10: ['broken lamp'],\n",
    "        11: ['tire flat'],\n",
    "        12: ['glass shatter'],\n",
    "        13: ['scratch', 'dent'],\n",
    "        14: ['scratch', 'car_damages_confdent'],\n",
    "        15: ['broken lamp'],\n",
    "        16: [],\n",
    "        17: ['scratch', 'dent'],\n",
    "        18: ['scratch', 'dent'],\n",
    "        19: ['scratch', 'dent'],\n",
    "        20: ['scratch', 'dent'],\n",
    "    }\n",
    "    if nombre_de_clase_2 in diccionario_combinaciones_posibles[numero_de_clase]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28665b-a3a7-42d3-9986-3f74bb6338a5",
   "metadata": {},
   "source": [
    "Función que devuelve True si la imagen 'imagen_aux' se parece al menos en un 70% a alguna de las imagenes del array 'imagenes' y False en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908d7f42-8384-4659-9781-6fb90fb90edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misma_imagen(imagenes, imagen_aux):\n",
    "    for element in imagenes:\n",
    "        parecido = calcular_similitud_histograma(element, imagen_aux)\n",
    "        if parecido >= 0.8:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885ce48-6f01-4f53-8b0e-c5a1af2dbf82",
   "metadata": {},
   "source": [
    "Función que guarda una imagen en una ruta determinada. Tambien almacena dicha imagen en formato array al array 'imagenes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3d5b3a-ba48-4365-a094-389d5d143196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_imagen(ruta_para_guardar, imagen_aux):\n",
    "    # Guardo la imagen:\n",
    "    cv2.imwrite(ruta_para_guardar, imagen_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e8a43-2e8f-4d42-ae1f-ecc61ca695c9",
   "metadata": {},
   "source": [
    "Función que añade al array 'damages' la información de las predicciones. Este array se enviará desde el endpoint al cliente que hace la llamada al endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8274bfc-a66a-4fb4-a548-62120651e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anadir_info_del_dano(ruta_para_guardar, conf_damage, nombre_de_clase_1, nombre_de_clase_2, damages):\n",
    "    damages_traduction = {\n",
    "\t\"broken lamp\": \"faro roto\",\n",
    "\t\t\"glass shatter\": \"cristal roto\",\n",
    "\t\t\"scratch\": \"rallada\",\n",
    "\t\t\"dent\": \"bolladura\",\n",
    "\t\t\"tire flat\": \"rueda pinchada\"\n",
    "}\n",
    "    \n",
    "    info = {\n",
    "        'car_damage_route' : ruta_para_guardar,\n",
    "        'car_damage_conf' : conf_damage,\n",
    "        'car_part_name' : nombre_de_clase_1,\n",
    "        'car_damage' : damages_traduction[nombre_de_clase_2],\n",
    "    }\n",
    "\n",
    "    damages.append(info)\n",
    "    return damages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765f687-b87c-4c08-911f-a6d2b20fac3a",
   "metadata": {},
   "source": [
    "Función que devuelve True si la confianza de la predicción está por encima del valor mínimo para cada etiqueta; devuelve False en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d9bbc4-8c5f-4246-8782-a004592749a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_confidence_sufficient(nombre_de_clase_2, conf_damage):\n",
    "\n",
    "    mult = .8\n",
    "    \n",
    "    car_damages_config = {\n",
    "            \"broken lamp\": 0.94 * mult,\n",
    "            \"glass shatter\": 0.88 * mult,\n",
    "            \"scratch\": 0.88 * mult,\n",
    "            \"dent\": 0.81 * mult,\n",
    "            \"tire flat\": 0.95 * mult\n",
    "        }\n",
    "\n",
    "    if conf_damage >= car_damages_config[nombre_de_clase_2]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c359e-8d06-4cb0-b2c3-c6ee5f6a1eab",
   "metadata": {},
   "source": [
    "Función que, dado un array de una imagen y las coordenadas de un cuadrado, devuelve la misma imagen con el cuadrado marcado en color rojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d615d820-8ae2-4bba-98a8-271c4265bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_red_square(image_array, coords):\n",
    "    image_with_square = image_array.copy()\n",
    "\n",
    "    height, width, _ = image_with_square.shape\n",
    "\n",
    "    x_min = int(coords[0] * width)\n",
    "    y_min = int(coords[1] * height)\n",
    "    x_max = int(coords[2] * width)\n",
    "    y_max = int(coords[3] * height)\n",
    "\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "\n",
    "    cv2.rectangle(image_with_square, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "\n",
    "    return image_with_square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f93f7-f9cf-4b01-8495-26e4168cf573",
   "metadata": {},
   "source": [
    "Se definen las variables de la ruta donde están los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158cf620-d98b-4279-9e87-384d5045a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_damgs_model_path = os.getcwd() + '/recursos adicionales/car_damages/train/weights/best.pt'\n",
    "car_parts_model_path = os.getcwd() + '/recursos adicionales/car_parts/train/weights/best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac21bec-6dc0-4e81-a1b4-b63b51676ddf",
   "metadata": {},
   "source": [
    "Se define la variable de la ruta de un video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a4058d9-cd45-4fb9-9d7b-ae2421db2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.getcwd() + '/as.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68880985-e4e3-45e2-973b-98c5df271324",
   "metadata": {},
   "source": [
    "Se define la función principal que devuelve las predicciones (en la memoria escrita se detalla como funciona cada trozo de código):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e032585f-e127-46c0-88dc-24febbd8c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(car_parts_model_path, car_damgs_model_path, video_path):\n",
    "    num_of_image = 0\n",
    "    damages = []\n",
    "    imagenes = []\n",
    "    frames_array = []\n",
    "    damages_arr = []\n",
    "    \n",
    "    # Paso los videos a un array de frames:\n",
    "    frames_array = convertVideoToFramesArray(video_path)\n",
    "\n",
    "    # Itero sobre todos los frames del video:\n",
    "    for frame_index, frame in enumerate(frames_array):\n",
    "        # Predigo las partes del vehículo:\n",
    "        results = YOLO(car_parts_model_path).predict(source=frame, save=False, show=False, device='cpu', conf=0.8, verbose=False)\n",
    "        \n",
    "        for element in results[0].boxes:\n",
    "            parte_de_la_imagen = obtener_imagen(element.xyxyn.tolist()[0], frame)\n",
    "            numero_de_clase = int(element.cls.tolist()[0])\n",
    "            nombre_de_clase_1 = results[0].names[numero_de_clase]\n",
    "    \n",
    "            # Predigo los daños del vehículo:\n",
    "            results_2 = YOLO(car_damgs_model_path).predict(source=parte_de_la_imagen, save=False, show=False, device='cpu', verbose=False)\n",
    "    \n",
    "            # Itero sobre los resultados de las predicciones de los daños del vehículo detectados:\n",
    "            for element_2 in results_2[0].boxes:\n",
    "                numero_de_clase_2 = int(element_2.cls.tolist()[0])\n",
    "                parte_de_la_imagen_2 = obtener_imagen(element_2.xyxyn.tolist()[0], parte_de_la_imagen)\n",
    "                nombre_de_clase_2 = results_2[0].names[numero_de_clase_2]\n",
    "                conf_damage = float(element_2.conf.tolist()[0])\n",
    "            \n",
    "                if is_damage_possible(nombre_de_clase_2, numero_de_clase) and is_confidence_sufficient(nombre_de_clase_2, conf_damage):\n",
    "                        damages_arr.append([frame_index, numero_de_clase, numero_de_clase_2])\n",
    "                        num_of_image = num_of_image + 1\n",
    "                        imagen_aux = cv2.resize(parte_de_la_imagen, (256, 256))\n",
    "                        imagen_aux_square = draw_red_square(imagen_aux, element_2.xyxyn.tolist()[0])\n",
    "                    \n",
    "                        if len(imagenes) == 0 or not misma_imagen(imagenes, imagen_aux_square):\n",
    "                            print('entro')\n",
    "                            # Guardo la imagen en la carpeta del dataset:\n",
    "                            os.makedirs('retrained-dataset/images/', exist_ok=True)\n",
    "                            ruta_imagen_ds = 'retrained-dataset/images/'  + video_path.split('/')[-1].split('.')[0] + '_' + str(num_of_image) + '.jpg'\n",
    "                            guardar_imagen(ruta_imagen_ds, imagen_aux)\n",
    "\n",
    "                            # Guardo la label en la carpeta del dataset:\n",
    "                            os.makedirs('retrained-dataset/labels/', exist_ok=True)\n",
    "                            ruta_label_ds = 'retrained-dataset/labels/'  + video_path.split('/')[-1].split('.')[0] + '_' + str(num_of_image) + '.txt'\n",
    "                            createTxtFile([nombre_de_clase_2], ruta_label_ds, ' , '.join(map(str, element_2.xyxyn.tolist()[0])))\n",
    "\n",
    "                            # Guardo la imagen para poder verla desde la web:\n",
    "                            os.makedirs('web-images/', exist_ok=True)\n",
    "                            ruta_imagen_web = 'web-images/' + video_path.split('/')[-1].split('.')[0] + '_' + str(num_of_image) + '.jpg'\n",
    "                            guardar_imagen(ruta_imagen_web, imagen_aux_square)\n",
    "\n",
    "                            # Guardo la imagen en el array:\n",
    "                            imagenes.append(imagen_aux_square)\n",
    "            \n",
    "                            damages = anadir_info_del_dano(ruta_imagen_web, conf_damage, nombre_de_clase_1, nombre_de_clase_2, damages)\n",
    "    return damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01db2299-72fe-4ec7-b1b4-b258496c4f75",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Usuario\\\\Documents\\\\MASTER\\\\recursos adicionales\\\\Notebooks\\\\recursos adicionales\\\\car_parts\\\\train\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m main(car_parts_model_path, car_damgs_model_path, video_path)\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(car_parts_model_path, car_damgs_model_path, video_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Itero sobre todos los frames del video:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_index, frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(frames_array):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Predigo las partes del vehículo:\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     results \u001b[38;5;241m=\u001b[39m YOLO(car_parts_model_path)\u001b[38;5;241m.\u001b[39mpredict(source\u001b[38;5;241m=\u001b[39mframe, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes:\n\u001b[0;32m     17\u001b[0m         parte_de_la_imagen \u001b[38;5;241m=\u001b[39m obtener_imagen(element\u001b[38;5;241m.\u001b[39mxyxyn\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m], frame)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:146\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(model, task\u001b[38;5;241m=\u001b[39mtask)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:289\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    286\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m attempt_load_one_weight(weights)\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:908\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m torch_safe_load(weight)  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    909\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:835\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 835\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(file, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _torch_load(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Usuario\\\\Documents\\\\MASTER\\\\recursos adicionales\\\\Notebooks\\\\recursos adicionales\\\\car_parts\\\\train\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "a = main(car_parts_model_path, car_damgs_model_path, video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a0eb6-a0fd-4abe-bde6-7d02c7ab72dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
